---
title: "R MarkDown - Rain Forecast Project"
author: "Alexandre Marette"
date: "31 aout 2019"
output: 
  html_document:
    theme: united
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Etape 0 - Nettoyage de l'environnement

```{r}
rm(list=ls())
list=ls()
```

# Etape 1 - Import du fichier de training


```{r}
train_meteo = read.csv("meteo.train.csv", na.strings = "")
```


# Etape 2 - Nettoyage et selection des donnees

```{r}

#Installation du package questionr
#install.packages("questionr")
library(questionr)

View(train_meteo)
#summary(train_meteo)
names(train_meteo)
attach(train_meteo)

#Verification pas de ligne vide
freq(train_meteo$pluie.demain)

#levels(train_meteo$pluie.demain)
#Calcul du nombre de lignes et de colonnes dans le fichier
nb_lignes = nrow(train_meteo)
nb_colonnes = ncol

```
## Suppression des colonnes heures et minutes (ne contiennent que des valeurs nulles)

```{r}
tr_meteo = cbind(train_meteo[,1:4],train_meteo[,7:ncol(train_meteo)])
attach(tr_meteo)
```

## Etude des correlations entre les variables explicatives

```{r include=FALSE}
#install.packages("Hmisc")
library(Hmisc)
library(corrplot)
```
```{r}
matrice_cor = cor(tr_meteo,method = c("pearson"))
plot.new()
corrplot(matrice_cor, type="upper", order="original",
         tl.col="black", tl.srt=45,tl.cex = 0.45)

```

En premiere approche, on remarque que les variables de vitesse du vent sont correlees positivement entre elles. Les co-variables de temperatures egalement, ainsi que certaines donnees relatives a l humidite et a la pression.

### Essayons d'etudier ces correlations plus en detail :

a- D'abord la vitesse et la direction du vent :


```{r}
#selection des variables :
tr_wind = cbind(tr_meteo[,16:22],tr_meteo[,37:44])
# calcul de la matrice de correlation
cor_wind=cor(tr_wind,method = c("pearson"))
# Graph de la matrice de corrélation
plot.new()
corrplot(cor_wind, type="upper", order="original",
         tl.col="black", tl.srt=45,tl.cex = 0.6)
```

- les variables concernant le vent les moins correlees aux autres sont les variables de direction moyenne
=> Nous allons les conserver.
- Les variables de vitesse du vent sont toutes correlees entre elles.
=> Nous allons tester en ne prenant que les valeurs moyennes.

b- Analyse des correlations sur les temperatures, l'humidite et la pression

```{r}
tr_tHp = cbind(tr_meteo[,5:5],tr_meteo[,23:24],tr_meteo[,6:6],tr_meteo[,25:26],tr_meteo[,7:7],tr_meteo[,27:28])
cor_tHp = cor(tr_tHp,method = c("pearson"))
plot.new()
corrplot(cor_tHp, type="upper", order="original",
         tl.col="black", tl.srt=45,tl.cex = 0.6)
```

Cette analyse conforte les conclusions precedentes.
Nous allons tester en prenant les variables moyennes.

## Construction du dataset a partir des resultats precedents :

- Nous allons eliminer les variables temporelles qui ne nous paraissent pas apporter d'information particuliere dans le cadre de ce projet, meme si on peut se poser la question d'une tendance et de la probabilite de pluie si la veille il a plu.
Mais cela semble sortir du cadre de ce cours.
- Nous conservons les variables de direction moyennes du vent et de vitesse moyennes du vent.
- Nous conservons les variables moyennes d'humidite, de temperatures et de pression.


```{r}
t_meteo = cbind(tr_meteo[,1],tr_meteo[,5:22],tr_meteo[,29:36],tr_meteo[,45])
names(t_meteo)[1]="X"
names(t_meteo)[28]="pluie.demain"

```


# Etape 3 - Preparation de la Validation Croisee : creation du jeu de donnee d'entrainement et du jeu de test  

On cree un vecteurs de booleens, tires aleatoirement :
- les valeurs TRUE correspondent aux individus de la base d'entrainement
- les valeurs FALSE correspondent aux individus de la base de test

```{r}
train = sample(c(T, F), nrow(t_meteo), replace = T, prob = c(.75, .25))
length(train)
nrow(t_meteo)
names(t_meteo)
```

# Etape 4 - Construction du modele et choix du modele 

## Echauffement 1 : regression de test Logit

### Premiere regression logit binaire sur l'ensemble des variables explicatives

```{r cache=TRUE}
reg_log = glm(pluie.demain ~ ., 
           data = t_meteo[train,], family = binomial(logit))
summary(reg_log)
```

D'apres les p-values, les covariables significatives sont les suivantes :

- Mean.Sea.Level.Pressure.daily.mean..MSL.     ***
- Wind.Direction.daily.mean..900.mb.           ***
- Medium.Cloud.Cover.daily.max..mid.cld.lay.   **
- Low.Cloud.Cover.daily.min..low.cld.lay.      *


```{r}
#Calcul des VIF entre les covariables  :
library(faraway)
#install.packages("fmsb")
vif(reg_log)
```

Les variables sont tres correlees entre elles, nous avons donc un probleme de multicolinearite dans le modele reg.

### Deuxieme regression logit binaire sur les variables explicatives les plus significatives

```{r cache=TRUE}
reg1_log = glm(pluie.demain ~ Mean.Sea.Level.Pressure.daily.mean..MSL. + Wind.Direction.daily.mean..900.mb. + Medium.Cloud.Cover.daily.max..mid.cld.lay. + Low.Cloud.Cover.daily.min..low.cld.lay., data = t_meteo[train,], family = binomial(logit))
summary(reg1_log)
```
Calul des VIF

```{r}
vif(reg1_log)
```

Bien que beaucoup plus faibles que precedemment les VIF sont encore un peu eleves (> 5), mais acceptable car < 10

Calcul de la déviance du model reg1_log,la sortie indique :

- Null deviance: 1301.6  on 938   degrees of freedom
- Residual deviance:  1080.8  on 934  degrees of freedom

```{r}
# Le test par rapport au modèle sans covariable donne
pchisq(1301.6 - 1080.8, 938 - 934, lower = F)
```

=> p-valeur tres faible : on rejette le modele sans covariable

```{r}
# Le test par rapport au modèle saturé donne
pchisq(1080.8, 934, lower = F)
```
=> p-valeur est faible : notre modele ne suffit pas a expliquer toutes les variations. Il est mal ajuste. Il est trop parcimonieux, il manque des variables explicatives.


## Echauffement 2 : regression de test Probit

### Premiere regression probit binaire sur l'ensemble des variables explicatives

```{r cache=TRUE}
reg_prob = glm(pluie.demain ~ ., 
           data = t_meteo[train,], family = binomial(link = "probit"))
summary(reg_prob)
```

D'apres les p-values, les covariables significatives sont les suivantes :

- Mean.Sea.Level.Pressure.daily.mean..MSL.     ***
- Wind.Direction.daily.mean..900.mb.           ***
- Medium.Cloud.Cover.daily.max..mid.cld.lay.   ***
- Low.Cloud.Cover.daily.min..low.cld.lay.      *

### Deuxieme regression probit binaire sur les variables explicatives les plus significatives

```{r cache=TRUE}
reg1_prob = glm(pluie.demain ~ Mean.Sea.Level.Pressure.daily.mean..MSL. +  Wind.Direction.daily.mean..900.mb. + Medium.Cloud.Cover.daily.max..mid.cld.lay. + Low.Cloud.Cover.daily.min..low.cld.lay., 
           data = t_meteo[train,], family = binomial(link = "probit"))
summary(reg1_prob)
```

Calul des VIF

```{r}
vif(reg1_prob)
```

Les VIF sont tres < 5, ils sont donc faibles. Il n'y a pas de colinearite entre les variables.

Calcul de la deviance du modele reg1_prob,la sortie indique :

- Null deviance: 1312.6  on 946   degrees of freedom
- Residual deviance:  1088.7  on 942  degrees of freedom

```{r}
# Le test par rapport au modèle sans covariable donne
pchisq(1312.6 - 1088.7, 946 - 942, lower = F)
```

=> p-valeur tres faible : on rejette le modele sans covariable

```{r}
# Le test par rapport au modèle saturé donne
pchisq(1088.7, 942, lower = F)
```
=> p-valeur est faible : notre modele ne suffit pas a expliquer toutes les variations. Il est mal ajuste. Il est trop parcimonieux, il manque des variables explicatives.

Cette méthode de construction de modele n'est pas satisfaisante. Dans la suite, nous allons tester des méthodes de choix plus industrielle, afin d'automatiser le processus de choix de modele : la methode exhaustive et les procédures pas à pas.

## La methode exhaustive

```{r}
#install.packages("glmulti")
#install.packages('rJava')
#library(glmulti)

#model_choice_Exh = glmulti(pluie.demain ~ 1,data = t_meteo[train,],level = 1,method = "h",fitfunction = glm,crit = 'aic',plotty = F)
```

Je n'ai malheureusement pas pu tester cette methode a cause d'un probleme technique

## Modele LOGIT avec la methode pas à pas

### Methode pas à pas avec le critere d'information d'Akaike, (en anglais Akaike information criterion ou AIC)

```{r}
library(MASS)
```
1- Procedure descendante

```{r cache=TRUE}

m1_log_aic = stepAIC(reg_log,trace = 1,direction = "backward")
summary(m1_log_aic)

```


Calul des VIF

```{r}
vif(m1_log_aic)
```

Les VIF sont > 5 voir tres > 5, ils sont eleves. Il y a, donc, de la colinearite entre les variables.

Calcul de la deviance du modele m1_log_aic,la sortie indique :

- Null deviance: 1286.4  on 927   degrees of freedom
- Residual deviance:  1029.8  on 917  degrees of freedom

```{r}
# Le test par rapport au modèle sans covariable donne
pchisq(1286.4 - 1029.8, 927 - 917, lower = F)
```

=> p-valeur tres faible : on rejette le modele sans covariable

```{r}
# Le test par rapport au modèle saturé donne

pchisq(1019.1, 926, lower = F)
#pchisq(1029.8, 917, lower = F)
```
=> p-valeur est faible : notre modele ne suffit pas a expliquer toutes les variations. Il est mal ajuste. Il est trop parcimonieux, il manque des variables explicatives.


2- Procedure ascendante

```{r cache=TRUE}
reg0 = glm(pluie.demain ~ 1,data = t_meteo[train,],family = binomial(logit))
m2_log_aic = stepAIC(reg0,scope=list(upper=reg_log),direction = "forward")
summary(m2_log_aic)

```
Calul des VIF

```{r}
vif(m2_log_aic)
```

Les VIF sont > 5, mais < 10. Ils sont un peu eleves, mais pas suffisamment pour que cela pose un problème de colinearite.

Calcul de la deviance du modele m2_log_aic,la sortie indique :

- Null deviance: 1268.4  on 914   degrees of freedom
- Residual deviance:  1040.0  on 908  degrees of freedom

```{r}
# Le test par rapport au modèle sans covariable donne
pchisq(1268.4 - 1040.0, 914 - 908, lower = F)
```

=> p-valeur tres faible : on rejette le modele sans covariable

```{r}
# Le test par rapport au modèle saturé donne

pchisq(1040.0, 908, lower = F)
#pchisq(1029.8, 917, lower = F)
```
=> p-valeur est faible : notre modele ne suffit pas a expliquer toutes les variations. Il est mal ajuste. Il est trop parcimonieux, il manque des variables explicatives.


3- Procedure Stepwise

```{r cache=TRUE}
m3_log_aic = stepAIC(reg_log,scope=list(lower=reg0,upper=reg_log),direction = "both")
summary(m3_log_aic)

```

Calul des VIF

```{r}
vif(m3_log_aic)
```

Les VIF sont > 5 a tres > 5, voir tres > 10. Il semble qu'il y ait de la colinearite entre les variables.

Calcul de la deviance du modele m3_log_aic,la sortie indique :

- Null deviance: 1313.5  on 947   degrees of freedom
- Residual deviance:  1060.2  on 935  degrees of freedom

```{r}
# Le test par rapport au modèle sans covariable donne
pchisq(1313.5 - 1060.2, 947 - 935, lower = F)
```

=> p-valeur tres faible : on rejette le modele sans covariable

```{r}
# Le test par rapport au modèle saturé donne

pchisq(1060.2, 935, lower = F)

```
=> p-valeur est faible : notre modele ne suffit pas a expliquer toutes les variations. Il est mal ajuste. Il est trop parcimonieux, il manque des variables explicatives.

### Methode pas a pas avec le critere d'information bayesien (en anglais bayesian information criterion ou BIC)

1- Procedure descendante
```{r cache=TRUE}

m1_log_bic = stepAIC(reg_log,trace = 1,direction = "backward",k = log(nrow(t_meteo)))
summary(m1_log_bic)

```

Calul des VIF

```{r}
vif(m1_log_bic)
```

Les VIF sont entre 5 et 10. Ce n'est pas suffisant pour en conclure qu'il y a de la colinearite entre les variables.

Calcul de la deviance du modele reg1_prob,la sortie indique :

- Null deviance: 1301.7  on 938   degrees of freedom
- Residual deviance:  1049.4  on 926  degrees of freedom

```{r}
# Le test par rapport au modèle sans covariable donne
pchisq(1301.7 - 1049.4, 938 - 926, lower = F)
```

=> p-valeur tres faible : on rejette le modele sans covariable

```{r}
# Le test par rapport au modèle saturé donne

pchisq(1049.4, 926, lower = F)
#pchisq(1029.8, 917, lower = F)
```
=> p-valeur est faible : notre modele ne suffit pas a expliquer toutes les variations. Il est mal ajuste. Il est trop parcimonieux, il manque des variables explicatives.


2- Procedure ascendante

```{r cache=TRUE}
reg0 = glm(pluie.demain ~ 1,data = t_meteo[train,],family = binomial(logit))
m2_log_bic = stepAIC(reg0,scope=list(lower=reg0, upper=reg_log),direction = "forward",k = log(nrow(t_meteo)))
summary(m2_log_bic)

```
Calul des VIF

```{r}
vif(m2_log_bic)
```

Les VIF sont > 5, mais < 10. Ils sont un peu eleves, mais pas suffisamment pour que cela pose un problème de colinearite.

Calcul de la deviance du modele m2_log_aic,la sortie indique :

- Null deviance: 1274.5  on 919   degrees of freedom
- Residual deviance:  1067.2  on 915  degrees of freedom

```{r}
# Le test par rapport au modèle sans covariable donne
pchisq(1274.5 - 1067.2, 919 - 915, lower = F)
```

=> p-valeur tres faible : on rejette le modele sans covariable

```{r}
# Le test par rapport au modèle saturé donne

pchisq(1067.2, 915, lower = F)

```
=> p-valeur est très faible : notre modele ne suffit pas a expliquer toutes les variations. Il est mal ajuste. Il est trop parcimonieux, il manque des variables explicatives.

3- Procedure Stepwise

la procédure stepwise donne des resultats similaires
Il semble que la procedure de selection des variables explicatives basees sur les correlations ne soit pas efficace.
Nous allons tester une autre approche en appliquant la methode pas a pas a l'ensemble des variables explicatives.

## Construction du modèle à partir de l'ensemble des variables


### Modele LOGIT avec la methode pas a pas

1. Methode pas a pas avec le critere d'information d'Akaike, (en anglais Akaike information criterion ou AIC)

1.1 Procedure descendante

```{r cache=TRUE}

#tr_meteo = cbind(tr_meteo[,1],tr_meteo[,5:ncol(tr_meteo)])
names(tr_meteo)
#names(tr_meteo)[1]="X"

reg_log_all = glm(pluie.demain ~ ., 
           data = tr_meteo[train,], family = binomial(logit))
summary(reg_log_all)

m1_log_aic_all = stepAIC(reg_log_all,~.,trace=TRUE,direction = "backward")
summary(m1_log_aic_all)

```


```{r}
# Le test par rapport au modèle sans covariable donne
#pchisq(1286.4 - 1029.8, 927 - 917, lower = F)
```

=> p-valeur tres faible : on rejette le modele sans covariable

```{r}
# Le test par rapport au modèle saturé donne

pchisq(994.87, 889, lower = F)

```
=> p-valeur est faible : notre modele ne suffit pas a expliquer toutes les variations. Il est mal ajuste. Il est trop parcimonieux, il manque des variables explicatives.

### Modele PROBIT avec la methode pas a pas

1. Methode pas a pas avec le critere d'information d'Akaike, (en anglais Akaike information criterion ou AIC)

1.1 Procedure descendante

```{r cache=TRUE}

#tr_meteo = cbind(tr_meteo[,1],tr_meteo[,5:ncol(tr_meteo)])
names(tr_meteo)
#names(tr_meteo)[1]="X"

reg_prob_all = glm(pluie.demain ~ ., 
           data = tr_meteo[train,], family = binomial(link = "probit"))
summary(reg_prob_all)

m1_prob_aic_all = stepAIC(reg_prob_all)
summary(m1_prob_aic_all)

```

# Etape 5 - Validation croisee 

## On effectue une prediction, uniquement sur la base de test

```{r cache=TRUE}
pred_log = predict(m1_log_aic_all, tr_meteo[!train, ], type = "response")
pred_prob = predict(m1_prob_aic_all, tr_meteo[!train, ], type = "response")
```

## Evaluation de l'erreur de prediction

```{r cache=TRUE}
mean(abs(pred_log - tr_meteo[!train, "pluie.demain"]), na.rm = T)
mean(abs(pred_prob - tr_meteo[!train, "pluie.demain"]), na.rm = T)
```

# Etape 6 - Prediction sur le jeu de test

```{r cache=TRUE}
test_meteo = read.csv("meteo.test.csv", na.strings = "")

prediction_final = predict(m1_prob_aic_all,test_meteo,type = "response")
pred_Final=prediction_final
pred_Final[pred_Final>0.5]=1 
pred_Final[pred_Final<=0.5]=0

print(pred_Final)

summary(prediction_final)
print(prediction_final)
```

# Etape 7 - Generation du fichier csv des predictions


```{r cache=TRUE}
test_meteo_output = cbind.data.frame(test_meteo,prediction_final,pred_Final)
head(test_meteo_output)
write.csv2(test_meteo_output,file = "fichier_preditctions_meteo.csv",dec=".",col.names = T)

```
